{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "Adjust as needed for project versions and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect = \"SD-1\"\n",
    "projVer = \"DS340\"\n",
    "numModels = 36\n",
    "\n",
    "sampleRate = 44100\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esrLoss(true, pred):\n",
    "    return tf.reduce_sum(tf.pow(true - pred,2), axis = 0) / tf.reduce_sum(tf.pow(true, 2), axis = 0) + 1e-50\n",
    "\n",
    "#Prepares test audio for prediction\n",
    "def predictionPrep(audio, samples):\n",
    "    chunks = []\n",
    "    for i in range(len(audio) - samples):\n",
    "        chunks.append(audio[i:i+samples])\n",
    "    return np.array(chunks)\n",
    "\n",
    "#Evaluates test audio\n",
    "#Due to how sequences are batched, there is an offset\n",
    "def evaluateNew(model, xTest, yTest, offset):\n",
    "    yPred = model.predict(predictionPrep(xTest, offset))\n",
    "    return esrLoss(yTest[offset:], yPred.squeeze()), yPred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS DOES NOT NEED TO BE RUN AGAIN IF MODEL RESULTS ARE STORED IN modelResults.pkl\n",
    "cols = [\"modelNum\", \"lstmUnits\", \"learningRate\", \"context\", \"gain\"]\n",
    "modelResults = pd.DataFrame(columns = cols)\n",
    "\n",
    "for i in range(numModels):\n",
    "    clear_session()\n",
    "    directory = f\"../Models/{effect}/{projVer}/Model_{i}\"\n",
    "    h5 = glob.glob(f\"{directory}/*.h5\")[0]\n",
    "    model = load_model(h5, custom_objects={\"esrLoss\": esrLoss})\n",
    "        \n",
    "    modelAttributes = h5.split(\"_\")\n",
    "\n",
    "    lvl = modelAttributes[2]\n",
    "    #print(lvl)\n",
    "    units = int(modelAttributes[3])\n",
    "    rate = float(modelAttributes[4])\n",
    "    context = int(modelAttributes[5])\n",
    "\n",
    "    #print(f\"{lvl} {units} {rate} {context}\")\n",
    "\n",
    "    modelRow = {\n",
    "\n",
    "        \"modelNum\" : i,\n",
    "        \"lstmUnits\" : units,\n",
    "        \"learningRate\" : rate,\n",
    "        \"context\" : context,\n",
    "        \"gain\" : lvl\n",
    "\n",
    "    }\n",
    "        \n",
    "    #did some organizational messing around here so all 24 wouldn't have the be evaluated\n",
    "    #ill fix the organization later\n",
    "\n",
    "    dataPath = f\"../Data/{effect}/{projVer}/Test/{lvl}\"\n",
    "    for _, _, files in os.walk(f\"{dataPath}/Dry\"):\n",
    "        for file in files:\n",
    "            fileName = file[2:]\n",
    "            dry, _ = lb.load(f\"{dataPath}/Dry/d_\" + fileName, sr=sampleRate, mono=True)\n",
    "            wet, _ = lb.load(f\"{dataPath}/Wet/w_\" + fileName, sr=sampleRate, mono=True)\n",
    "            #change evalutateNew to return a float not a tensor or something\n",
    "            loss, output = evaluateNew(model, dry, wet, context)\n",
    "            os.makedirs(f\"{directory}/Output\", exist_ok=True)\n",
    "            #or use PCM_16\n",
    "            sf.write(f\"{directory}/Output/o_{fileName}\", output, sampleRate, subtype = \"PCM_24\")\n",
    "            #creates new columns for the songs\n",
    "            if fileName not in modelResults.columns:\n",
    "                modelResults[fileName] = None \n",
    "            modelRow[fileName] = float(loss.numpy())\n",
    "            #print(fileName, float(loss.numpy()))\n",
    "    #check if this ordering is right later\n",
    "    modelResults = pd.concat([modelResults, pd.DataFrame([modelRow])], ignore_index = True)\n",
    "    #saves the results\n",
    "\n",
    "    outputDir = f\"../ModelResults/{effect}/{projVer}\"\n",
    "    os.makedirs(outputDir, exist_ok=True)\n",
    "    modelResults.to_pickle(f\"{outputDir}/{effect}_{projVer}_modelResults.pkl\")\n",
    "    #print(modelResults)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
